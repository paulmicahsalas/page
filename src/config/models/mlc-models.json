{
    "llama-3.2-1b-instruct": {
        "engine": "mlc",
        "modelName": "Llama-3.2-1b-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Llama-3.2-1B-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f32_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "pipeline": "text-generation"
    },
    "llama-3.2-3b-instruct": {
        "engine": "mlc",
        "modelName": "Llama-3.2-3B-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Llama-3.2-3B-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "pipeline": "text-generation",
        "metadata": {
            "context_window_size": 4096,
            "download_size_in_mb": {
                "q4f16_1": 1797,
                "q4f32_1": 1797
            },
            "estimated_vram_in_mb": {
                "q4f16_1": 1797,
                "q4f32_1": 1797
            }
        }
    },
    "hermes-llama-3.2-3b": {
        "engine": "mlc",
        "modelName": "hermes-llama-3.2-3b",
        "modelType": "text-generation",
        "repo": "mlc-ai/Hermes-3-Llama-3.2-3B-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "pipeline": "text-generation",
        "metadata": {
            "context_window_size": 4096,
            "download_size_in_mb": {
                "q4f16_1": 1797,
                "q4f32_1": 1797
            },
            "estimated_vram_in_mb": {
                "q4f16_1": 1797,
                "q4f32_1": 1797
            }
        }
    },
    "qwen2.5-3b-instruct": {
        "engine": "mlc",
        "modelName": "Qwen2.5-3B-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Qwen2.5-3B-Instruct-{quantization}-MLC",
        "quantizations": ["q4f32_1"],
        "defaultQuantization": "q4f32_1",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 4096
        },
        "pipeline": "text-generation"
    },  
    "smollm2-135m-instruct": {
        "engine": "mlc",
        "modelName": "SmolLM2-135M-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/SmolLM2-135M-Instruct-{quantization}-MLC",
        "quantizations": [
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q0f32",
        "defaultParams": {
            "temperature": 0.7,
            "maxTokens": 2048
        },
        "required_features": [
            "shader-f16"
        ],
        "overrides": {
            "context_window_size": 4096
        },
        "pipeline": "text-generation"
    },
    "smollm2-360m-instruct": {
        "engine": "mlc",
        "modelName": "SmolLM2-360M-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/SmolLM2-360M-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f32_1",
        "required_features": [
            "shader-f16"
        ],
        "defaultParams": {
            "temperature": 0.1,
            "maxTokens": 2048
        },
        "pipeline": "text-generation"
    },
    "smollm2-1.7b-instruct": {
        "engine": "mlc",
        "modelName": "SmolLM2-1.7B-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/SmolLM2-1.7B-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation",
        "defaultParams": {
            "temperature": 0.1,
            "maxTokens": 2048
        }
    },
    "qwen2.5-0.5b-instruct": {
        "engine": "mlc",
        "modelName": "Qwen2.5-0.5B-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Qwen2.5-0.5B-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1",
            "q0f32",
            "q0f16"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "gemma-2b-it": {
        "engine": "mlc",
        "modelName": "gemma-2b-it",
        "modelType": "text-generation",
        "repo": "mlc-ai/gemma-2b-it-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation",
        "required_features": [
            "shader-f16"
        ]
    },
    "tinyllama-1.1b-chat-v0.4": {
        "engine": "mlc",
        "modelName": "TinyLlama-1.1B-Chat-v0.4",
        "modelType": "text-generation",
        "repo": "mlc-ai/TinyLlama-1.1B-Chat-v0.4-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "phi-3.5-mini-instruct": {
        "engine": "mlc",
        "modelName": "Phi-3.5-mini-instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Phi-3.5-mini-instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "qwen2.5-1.5b-instruct": {
        "engine": "mlc",
        "modelName": "Qwen2.5-1.5B-Instruct",
        "modelType": "text-generation",
        "repo": "mlc-ai/Qwen2.5-1.5B-Instruct-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "deepseek-r1-distill-qwen-1.5b": {
        "engine": "mlc",
        "modelName": "DeepSeek-R1-Distill-Qwen-1.5B-MLC",
        "modelType": "text-generation",
        "modelLibrary": "Qwen2-1.5B-Instruct-q4f32_1-ctx4k_cs1k-webgpu.wasm",
        "repo": "sauravpanda/DeepSeek-R1-Distill-Qwen-1.5B-MLC",
        "quantizations": [
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "deepseek-r1-distill-qwen-7b": {
        "engine": "mlc",
        "modelName": "DeepSeek-R1-Distill-Qwen-7B",
        "modelType": "text-generation",
        "repo": "mlc-ai/DeepSeek-R1-Distill-Qwen-7B-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "deepseek-r1-distill-llama-8b": {
        "engine": "mlc",
        "modelName": "DeepSeek-R1-Distill-Llama-8B",
        "modelType": "text-generation",
        "repo": "mlc-ai/DeepSeek-R1-Distill-Llama-8B-{quantization}-MLC",
        "quantizations": [
            "q4f16_1",
            "q4f32_1"
        ],
        "defaultQuantization": "q4f32_1",
        "pipeline": "text-generation"
    },
    "snowflake-arctic-embed-m-b4": {
        "engine": "mlc",
        "modelName": "snowflake-arctic-embed-m-b4",
        "modelType": "embedding",
        "repo": "mlc-ai/snowflake-arctic-embed-m-{quantization}-MLC-b4",
        "quantizations": [
            "q0f32"
        ],
        "defaultQuantization": "q0f32",
        "pipeline": "embedding",
        "metadata": {
            "context_window_size": 512,
            "download_size_in_mb": {
                "q0f32": 218
            },
            "estimated_vram_in_mb": {
                "q0f32": 218
            }
        }
    },
    "snowflake-arctic-embed-s-b4": {
        "engine": "mlc",
        "modelName": "snowflake-arctic-embed-s-b4",
        "modelType": "embedding",
        "repo": "mlc-ai/snowflake-arctic-embed-s-{quantization}-MLC-b4",
        "quantizations": [
            "q0f32"
        ],
        "defaultQuantization": "q0f32",
        "pipeline": "embedding",
        "metadata": {
            "context_window_size": 512,
            "download_size_in_mb": {
                "q0f32": 66.4
            },
            "estimated_vram_in_mb": {
                "q0f32": 66.4
            }
        }
    },
    "snowflake-arctic-embed-m-b32": {
        "engine": "mlc",
        "modelName": "snowflake-arctic-embed-m-b32",
        "modelType": "embedding",
        "repo": "mlc-ai/snowflake-arctic-embed-m-{quantization}-MLC-b32",
        "quantizations": [
            "q0f32"
        ],
        "defaultQuantization": "q0f32",
        "pipeline": "embedding",
        "metadata": {
            "context_window_size": 512,
            "download_size_in_mb": {
                "q0f32": 218
            },
            "estimated_vram_in_mb": {
                "q0f32": 218
            }
        }
    },
    "snowflake-arctic-embed-s-b32": {
        "engine": "mlc",
        "modelName": "snowflake-arctic-embed-s-b32",
        "modelType": "embedding",
        "repo": "mlc-ai/snowflake-arctic-embed-s-{quantization}-MLC-b32",
        "quantizations": [
            "q0f32"
        ],
        "defaultQuantization": "q0f32",
        "pipeline": "embedding",
        "metadata": {
            "context_window_size": 512,
            "download_size_in_mb": {
                "q0f32": 66.4
            },
            "estimated_vram_in_mb": {
                "q0f32": 66.4
            }
        }
    }
}